{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "print(\"hello world\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>category</th>\n",
       "      <th>author_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بسم اللّه الرحمن الرحيم</td>\n",
       "      <td></td>\n",
       "      <td>government performance follow up</td>\n",
       "      <td>local news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بتمويل كويتي.. افتتاح مشروع للمياه في اليمن</td>\n",
       "      <td>\\\\n                                    (كونا) ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"</td>\n",
       "      <td>alwatan</td>\n",
       "      <td>local news</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سمو نائب الأمير وولي العهد يهنئ الملك تشارلز ا...</td>\n",
       "      <td>(كونا) - بعث سمو نائب الأمير وولي العهد الشيخ ...</td>\n",
       "      <td>alqabas</td>\n",
       "      <td>local news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>سمو الأمير يهنئ تشارلز الثالث بمناسبة إعتلائه ...</td>\n",
       "      <td>(كونا) - بعث سمو أمير البلاد الشيخ نواف الأحمد...</td>\n",
       "      <td>alqabas</td>\n",
       "      <td>local news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18709</th>\n",
       "      <td>مستقبل نرعاه بالمعرفة</td>\n",
       "      <td>تستند مؤسسة الكويت للتقدم العلمي إلى ثلاثة محا...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Sciences news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18710</th>\n",
       "      <td>لمزيد من المعلومات عن البرنامج التدريبي يرجى ا...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Sciences news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18711</th>\n",
       "      <td>تعلن مؤسسة الكويت للتقدم العلمي عن برنامج تدري...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Sciences news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18712</th>\n",
       "      <td>الأبحاث في مجال الوقود الأحفوري (التقليدي) وغي...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Sciences news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18713</th>\n",
       "      <td>أنجز المعهد مشروع \\التنبؤ بتأثير التغيرات المن...</td>\n",
       "      <td>\\N</td>\n",
       "      <td>\\N</td>\n",
       "      <td>Sciences news</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18714 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                                بسم اللّه الرحمن الرحيم   \n",
       "1            بتمويل كويتي.. افتتاح مشروع للمياه في اليمن   \n",
       "2                                                      \"   \n",
       "3      سمو نائب الأمير وولي العهد يهنئ الملك تشارلز ا...   \n",
       "4      سمو الأمير يهنئ تشارلز الثالث بمناسبة إعتلائه ...   \n",
       "...                                                  ...   \n",
       "18709                              مستقبل نرعاه بالمعرفة   \n",
       "18710  لمزيد من المعلومات عن البرنامج التدريبي يرجى ا...   \n",
       "18711  تعلن مؤسسة الكويت للتقدم العلمي عن برنامج تدري...   \n",
       "18712  الأبحاث في مجال الوقود الأحفوري (التقليدي) وغي...   \n",
       "18713  أنجز المعهد مشروع \\التنبؤ بتأثير التغيرات المن...   \n",
       "\n",
       "                                                contents  \\\n",
       "0                                                          \n",
       "1      \\\\n                                    (كونا) ...   \n",
       "2                                                alwatan   \n",
       "3      (كونا) - بعث سمو نائب الأمير وولي العهد الشيخ ...   \n",
       "4      (كونا) - بعث سمو أمير البلاد الشيخ نواف الأحمد...   \n",
       "...                                                  ...   \n",
       "18709  تستند مؤسسة الكويت للتقدم العلمي إلى ثلاثة محا...   \n",
       "18710                                                 \\N   \n",
       "18711                                                 \\N   \n",
       "18712                                                 \\N   \n",
       "18713                                                 \\N   \n",
       "\n",
       "                               category    author_name  \n",
       "0      government performance follow up     local news  \n",
       "1                                   NaN            NaN  \n",
       "2                            local news            NaN  \n",
       "3                               alqabas     local news  \n",
       "4                               alqabas     local news  \n",
       "...                                 ...            ...  \n",
       "18709                                \\N  Sciences news  \n",
       "18710                                \\N  Sciences news  \n",
       "18711                                \\N  Sciences news  \n",
       "18712                                \\N  Sciences news  \n",
       "18713                                \\N  Sciences news  \n",
       "\n",
       "[18714 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"arabic_data.csv\",on_bad_lines='skip')\n",
    "dataset.columns=[\"title\",\"contents\",\"category\",\"author_name\"]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13897 entries, 0 to 18713\n",
      "Data columns (total 4 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   title        13897 non-null  object\n",
      " 1   contents     13897 non-null  object\n",
      " 2   category     13897 non-null  object\n",
      " 3   author_name  13897 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 542.9+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.dropna(axis=0,inplace=True)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all special characters \n",
    "import re\n",
    "exp='[\\u0627-\\u064aA-Za-z]+' #re to get arabic and english , i had eliminated numbers and special characters because they dont have much influence \n",
    "dataset[\"contents\"]=dataset['contents'].apply(lambda data : \" \".join(re.findall(exp,data)))\n",
    "dataset[\"category\"]=dataset[\"category\"].apply(lambda data : \" \".join(re.findall(exp,data)))\n",
    "dataset[\"title\"]=dataset[\"title\"].apply(lambda data : \" \".join(re.findall(exp,data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_str_contents=dataset.loc[dataset[\"contents\"]==r\"\"].index\n",
    "empty_str_title=dataset.loc[dataset[\"title\"]==r\"\"].index\n",
    "empty_str_category=dataset.loc[dataset[\"category\"]==\"\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([    0,    36,   136,   208,   236,   340,  6256,  6258,  6274,\n",
       "             6451,  6472,  6488,  6566,  6642,  6647,  6682,  6726,  6727,\n",
       "             6747,  6773,  6870,  7157,  7471,  7498,  7516,  7523,  7531,\n",
       "             7533,  7536,  7538,  7565,  7569,  7577,  7589,  7597,  7606,\n",
       "             7609,  7612,  7632,  7649,  8822,  8870,  8879,  9925,  9946,\n",
       "            10029, 10041, 10067, 10375, 10400, 10453, 10660, 10664, 10682,\n",
       "            10717, 10720, 10726, 10728, 12863, 13025, 13041, 13407, 13926,\n",
       "            13934, 17336, 17638, 17844, 17847, 17852, 18408, 18492, 18493,\n",
       "            18521, 18537, 18569, 18579, 18582],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty_str_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(list(empty_str_contents),axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.drop(\"index\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13820, 4)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"keywords\"]=dataset[\"title\"]+\" \"+dataset[\"contents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>contents</th>\n",
       "      <th>category</th>\n",
       "      <th>author_name</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>سمو نا ب ال مير وولي العهد يهن الملك تشارلز ال...</td>\n",
       "      <td>كونا بعث سمو نا ب ال مير وولي العهد الشيخ مشعل...</td>\n",
       "      <td>alqabas</td>\n",
       "      <td>local news</td>\n",
       "      <td>سمو نا ب ال مير وولي العهد يهن الملك تشارلز ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>سمو ال مير يهن تشارلز الثالث بمناسبة عتلا ه ال...</td>\n",
       "      <td>كونا بعث سمو مير البلاد الشيخ نواف ال حمد ببرق...</td>\n",
       "      <td>alqabas</td>\n",
       "      <td>local news</td>\n",
       "      <td>سمو ال مير يهن تشارلز الثالث بمناسبة عتلا ه ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>مستشفى الطب الطبيعي والت هيل يحتفل باليوم العا...</td>\n",
       "      <td>احتفل مستشفى الطب الطبيعي والت هيل باليوم العا...</td>\n",
       "      <td>alqabas</td>\n",
       "      <td>local news</td>\n",
       "      <td>مستشفى الطب الطبيعي والت هيل يحتفل باليوم العا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>الهلال ال حمر تبد حملة جمع تبرعات لمتضرري الصو...</td>\n",
       "      <td>بد ت جمعية الهلال ال حمر اليوم السبت حملة جمع ...</td>\n",
       "      <td>alqabas</td>\n",
       "      <td>local news</td>\n",
       "      <td>الهلال ال حمر تبد حملة جمع تبرعات لمتضرري الصو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>السفارة البريطانية رفع العلم من ظهر اليوم حتى ...</td>\n",
       "      <td>مي السكري علنت السفارة البريطانية لدى البلاد ن...</td>\n",
       "      <td>alqabas</td>\n",
       "      <td>local news</td>\n",
       "      <td>السفارة البريطانية رفع العلم من ظهر اليوم حتى ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  سمو نا ب ال مير وولي العهد يهن الملك تشارلز ال...   \n",
       "1  سمو ال مير يهن تشارلز الثالث بمناسبة عتلا ه ال...   \n",
       "2  مستشفى الطب الطبيعي والت هيل يحتفل باليوم العا...   \n",
       "3  الهلال ال حمر تبد حملة جمع تبرعات لمتضرري الصو...   \n",
       "4  السفارة البريطانية رفع العلم من ظهر اليوم حتى ...   \n",
       "\n",
       "                                            contents category author_name  \\\n",
       "0  كونا بعث سمو نا ب ال مير وولي العهد الشيخ مشعل...  alqabas  local news   \n",
       "1  كونا بعث سمو مير البلاد الشيخ نواف ال حمد ببرق...  alqabas  local news   \n",
       "2  احتفل مستشفى الطب الطبيعي والت هيل باليوم العا...  alqabas  local news   \n",
       "3  بد ت جمعية الهلال ال حمر اليوم السبت حملة جمع ...  alqabas  local news   \n",
       "4  مي السكري علنت السفارة البريطانية لدى البلاد ن...  alqabas  local news   \n",
       "\n",
       "                                            keywords  \n",
       "0  سمو نا ب ال مير وولي العهد يهن الملك تشارلز ال...  \n",
       "1  سمو ال مير يهن تشارلز الثالث بمناسبة عتلا ه ال...  \n",
       "2  مستشفى الطب الطبيعي والت هيل يحتفل باليوم العا...  \n",
       "3  الهلال ال حمر تبد حملة جمع تبرعات لمتضرري الصو...  \n",
       "4  السفارة البريطانية رفع العلم من ظهر اليوم حتى ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rbw19\\OneDrive\\Desktop\\recommendation_engine\\minisom_arabic.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     keywords \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([x \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m keywords])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m keywords\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m dataset[\u001b[39m\"\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39mdataset[\u001b[39m\"\u001b[39;49m\u001b[39mkeywords\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m data:keyword_extractor(data))\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\core\\series.py:4356\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4246\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[0;32m   4247\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   4248\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4251\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m   4252\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m FrameOrSeriesUnion:\n\u001b[0;32m   4253\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4254\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4255\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4354\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4355\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4356\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\core\\apply.py:1036\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1032\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1033\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[0;32m   1034\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[1;32m-> 1036\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\core\\apply.py:1092\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1086\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1087\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[0;32m   1088\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[0;32m   1089\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[1;32m-> 1092\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[0;32m   1093\u001b[0m             values,\n\u001b[0;32m   1094\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1095\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[0;32m   1096\u001b[0m         )\n\u001b[0;32m   1098\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1099\u001b[0m     \u001b[39m# GH 25959 use pd.array instead of tolist\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m     \u001b[39m# so extension arrays can be used\u001b[39;00m\n\u001b[0;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(pd_array(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2859\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\rbw19\\OneDrive\\Desktop\\recommendation_engine\\minisom_arabic.ipynb Cell 13\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     keywords \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([x \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m keywords])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m keywords\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m dataset[\u001b[39m\"\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m=\u001b[39mdataset[\u001b[39m\"\u001b[39m\u001b[39mkeywords\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m data:keyword_extractor(data))\n",
      "\u001b[1;32mc:\\Users\\rbw19\\OneDrive\\Desktop\\recommendation_engine\\minisom_arabic.ipynb Cell 13\u001b[0m in \u001b[0;36mkeyword_extractor\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mkeyword_extractor\u001b[39m(data):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     keywords \u001b[39m=\u001b[39m kw_extractor\u001b[39m.\u001b[39;49mextract_keywords(text\u001b[39m=\u001b[39;49mdata)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     keywords \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([x \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m keywords])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m keywords\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\yake\\yake.py:64\u001b[0m, in \u001b[0;36mKeywordExtractor.extract_keywords\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n\u001b[0;32m     63\u001b[0m text \u001b[39m=\u001b[39m text\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 64\u001b[0m dc \u001b[39m=\u001b[39m DataCore(text\u001b[39m=\u001b[39;49mtext, stopword_set\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstopword_set, windowsSize\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwindowsSize, n\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn)\n\u001b[0;32m     65\u001b[0m dc\u001b[39m.\u001b[39mbuild_single_terms_features(features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n\u001b[0;32m     66\u001b[0m dc\u001b[39m.\u001b[39mbuild_mult_terms_features(features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\yake\\datarepresentation.py:30\u001b[0m, in \u001b[0;36mDataCore.__init__\u001b[1;34m(self, text, stopword_set, windowsSize, n, tagsToDiscard, exclude)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfreq_ns[i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0.\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstopword_set \u001b[39m=\u001b[39m stopword_set\n\u001b[1;32m---> 30\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build(text, windowsSize, n)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\yake\\datarepresentation.py:50\u001b[0m, in \u001b[0;36mDataCore._build\u001b[1;34m(self, text, windowsSize, n)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build\u001b[39m(\u001b[39mself\u001b[39m, text, windowsSize, n):\n\u001b[0;32m     49\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_filter(text)\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentences_str \u001b[39m=\u001b[39m [ [w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m split_contractions(web_tokenizer(s)) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (w\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(split_multi(text)) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(s\u001b[39m.\u001b[39mstrip()) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumber_of_sentences \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentences_str)\n\u001b[0;32m     52\u001b[0m     pos_text \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\yake\\datarepresentation.py:50\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_build\u001b[39m(\u001b[39mself\u001b[39m, text, windowsSize, n):\n\u001b[0;32m     49\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_filter(text)\n\u001b[1;32m---> 50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentences_str \u001b[39m=\u001b[39m [ [w \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m split_contractions(web_tokenizer(s)) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (w\u001b[39m.\u001b[39mstartswith(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(w) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(split_multi(text)) \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(s\u001b[39m.\u001b[39mstrip()) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m     51\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumber_of_sentences \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentences_str)\n\u001b[0;32m     52\u001b[0m     pos_text \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\segtok\\tokenizer.py:306\u001b[0m, in \u001b[0;36mweb_tokenizer\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39m@_matches\u001b[39m(\u001b[39mr\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m    281\u001b[0m \u001b[39m    (?<=^|[\u001b[39m\u001b[39m\\\u001b[39m\u001b[39ms<\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(\u001b[39m\u001b[39m\\\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39m\u001b[39m])            # visual border\u001b[39m\n\u001b[0;32m    282\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m)\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mweb_tokenizer\u001b[39m(sentence):\n\u001b[0;32m    302\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    303\u001b[0m \u001b[39m    The web tokenizer works like the :func:`word_tokenizer`, but does not split URIs or\u001b[39;00m\n\u001b[0;32m    304\u001b[0m \u001b[39m    e-mail addresses. It also un-escapes all escape sequences (except in URIs or email addresses).\u001b[39;00m\n\u001b[0;32m    305\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 306\u001b[0m     \u001b[39mreturn\u001b[39;00m [token \u001b[39mfor\u001b[39;00m i, span \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(web_tokenizer\u001b[39m.\u001b[39;49msplit(sentence))\n\u001b[0;32m    307\u001b[0m             \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m ((span,) \u001b[39mif\u001b[39;00m i \u001b[39m%\u001b[39m \u001b[39m2\u001b[39m \u001b[39melse\u001b[39;00m word_tokenizer(unescape(span)))]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#running this cell may take 30 mins\n",
    "from yake import KeywordExtractor\n",
    "kw_extractor = KeywordExtractor(lan=\"ar\", n=1, top=15) \n",
    "def keyword_extractor(data):\n",
    "    keywords = kw_extractor.extract_keywords(text=data)\n",
    "    keywords = \" \".join([x for x, y in keywords])\n",
    "    return keywords\n",
    "dataset[\"keywords\"]=dataset[\"keywords\"].apply(lambda data:keyword_extractor(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"processed_df.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOM  -- Self organizing Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minisom import MiniSom\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:1000]\n",
    "# Y=dataset.iloc[10000:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset[\"title\"]+dataset[\"contents\"]+dataset[\"category\"]+dataset[\"author_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tf_model_train=TfidfVectorizer()\n",
    "tf_model_test=TfidfVectorizer()\n",
    "tf_model_train.fit(X)\n",
    "tf_model_test.fit(Y)\n",
    "X=tf_model_train.transform(X)\n",
    "Y=tf_model_test.transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.DataFrame.sparse.from_spmatrix(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 12.8 GiB for an array with shape (13820, 124224) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rbw19\\OneDrive\\Desktop\\recommendation_engine\\minisom_arabic.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pca \u001b[39m=\u001b[39m PCA(n_components\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m x_train_pca \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mfit_transform(np\u001b[39m.\u001b[39;49marray(X))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X41sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m explained_variance \u001b[39m=\u001b[39m pca\u001b[39m.\u001b[39mexplained_variance_ratio_ \u001b[39m# maximum information  retained\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39msum\u001b[39m(explained_variance)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 12.8 GiB for an array with shape (13820, 124224) and data type float64"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=10)\n",
    "x_train_pca = pca.fit_transform(np.array(X))\n",
    "explained_variance = pca.explained_variance_ratio_ # maximum information  retained\n",
    "sum(explained_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 12.8 GiB for an array with shape (124224, 13820) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rbw19\\OneDrive\\Desktop\\recommendation_engine\\minisom_arabic.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X31sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m som \u001b[39m=\u001b[39mMiniSom(x\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m ,y\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m ,input_len\u001b[39m=\u001b[39m\u001b[39m124223\u001b[39m, sigma\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m , learning_rate\u001b[39m=\u001b[39m\u001b[39m0.5\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m som\u001b[39m.\u001b[39mrandom_weights_init(X\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/rbw19/OneDrive/Desktop/recommendation_engine/minisom_arabic.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m som\u001b[39m.\u001b[39mtrain_random(data\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mvalues, num_iteration\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\core\\frame.py:11761\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  11688\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  11689\u001b[0m \u001b[39mReturn a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  11690\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11758\u001b[0m \u001b[39m       ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  11759\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m  11760\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m> 11761\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mas_array()\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1747\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1745\u001b[0m             arr \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1746\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1747\u001b[0m     arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interleave(dtype\u001b[39m=\u001b[39;49mdtype, na_value\u001b[39m=\u001b[39;49mna_value)\n\u001b[0;32m   1748\u001b[0m     \u001b[39m# The underlying data was copied within _interleave\u001b[39;00m\n\u001b[0;32m   1749\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\anaconda\\envs\\machine_learning\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1786\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1783\u001b[0m \u001b[39melif\u001b[39;00m is_dtype_equal(dtype, \u001b[39mstr\u001b[39m):\n\u001b[0;32m   1784\u001b[0m     dtype \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 1786\u001b[0m result \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mempty(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshape, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[0;32m   1788\u001b[0m itemmask \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n\u001b[0;32m   1790\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39m==\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m na_value \u001b[39mis\u001b[39;00m lib\u001b[39m.\u001b[39mno_default:\n\u001b[0;32m   1791\u001b[0m     \u001b[39m# much more performant than using to_numpy below\u001b[39;00m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 12.8 GiB for an array with shape (124224, 13820) and data type float64"
     ]
    }
   ],
   "source": [
    "som =MiniSom(x=3 ,y=3 ,input_len=124223, sigma=1.0 , learning_rate=0.5)\n",
    "som.random_weights_init(X.values)\n",
    "som.train_random(data=X.values, num_iteration=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('machine_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a9c62d8cf6e30c1639f8e9a0a261a530483935ac00f94e2882c1ade2d532fd4c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
